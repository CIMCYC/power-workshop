---
title: "Simulation-Based Power Analysis"
subtitle: "Final part: Power analysis accoss varying sample sizes and effect sizes"
format:
  revealjs:
    theme: serif
    css: custom.css
    slide-number: true
    chalkboard: true
    code-fold: false
    code-overflow: wrap
    scrollable: true
---

## Part 8: Power analysis across varying sample sizes and effect sizes

```{r}
#| echo: false
#| eval: true

# load packages
library(tictoc)
library(MASS)
library(lme4)
library(lmerTest)
library(ggplot2)

options(scipen = 999) # prevents scientific notation
set.seed(42) # set seed for reproducibility
```

```{r}
#| echo: false
#| eval: true

# Function to generate log-normal LDT data in a fully crossed design
gendat_ldt_crossed_log <- function(n = 20,          # subjects
                                   k = 20,          # 20 per condition
                                   b0 = 6.59,       # grand mean log(RT) (exp(6.55) ≈ 700ms)
                                   b1 = 0.10,       # log-scale frequency effect (≈70 on RT scale)
                                   sigma_u0 = 0.2,  # SD of subject random intercepts (log scale)
                                   sigma_u1 = 0.02, # SD of subject random slopes (log scale)
                                   rho = -0.5,      # correlation between subject intercepts and slopes
                                   sigma_w = 0.1,   # SD of item random INTERCEPTS only (log scale)
                                   sigma = 0.25){   # residual SD (log scale)

  # Create fully crossed design: each subject sees all items
  sim_dat <- expand.grid(item = 1:(k*2), subj = 1:n)

  # Assign items to conditions (half low, half high frequency)
  sim_dat$cond.cod <- rep(c(-0.5, 0.5), each = k)

  # Build variance-covariance matrix for subjects from individual parameters
  Sigma_u <- matrix(c(sigma_u0^2, rho * sigma_u0 * sigma_u1,
                      rho * sigma_u0 * sigma_u1, sigma_u1^2), nrow = 2)

  # Subject random effects (intercepts AND slopes):
  u <- mvrnorm(n = length(unique(sim_dat$subj)),
               mu = c(0,0), 
               Sigma = Sigma_u)

  # Item random effects (intercepts ONLY):
  w <- rnorm(n = length(unique(sim_dat$item)), mean = 0, sd = sigma_w)

  # generate data row by row:
  N <- dim(sim_dat)[1]
  rt <- rep(NA, N)
  for(i in 1:N){
    rt[i] <- rlnorm(1, b0 +                     # grand mean
                        u[sim_dat[i,]$subj,1] + # subject random intercept
                        w[sim_dat[i,]$item] +   # item random intercept
                      (b1 + 
                        u[sim_dat[i,]$subj,2]) * sim_dat[i,]$cond.cod,
                     sigma)                     # residual error
  }
  sim_dat$rt <- rt
  sim_dat$subj <- factor(sim_dat$subj)
  sim_dat$item <- factor(sim_dat$item)
  sim_dat
}
```

**Now we are ready to simulate power for different combinations of:**

::: incremental
-   Sample sizes (number of subjects)
-   Effect sizes (b1 on log scale)
:::

## Part 8: Power analysis across varying sample sizes and effect sizes

**Now we are ready to simulate power for different combinations of:**

-   Sample sizes (number of subjects)
-   Effect sizes (b1 on log scale)

```{r}
#| echo: true
#| eval: true

# Define number of subjects:
n_subj <- c(24, 36, 48, 60, 72, 84, 96)

# Define effect sizes to test:
effect_sizes <- c(0.06, 0.10, 0.14)

# Fixed number of items
n_item <- 40  

# Create a grid to store results
power_grid <- expand.grid(n = n_subj,
                          b1 = effect_sizes)
power_grid$power <- NA
power_grid
```

## Part 8: Power analysis across varying sample sizes and effect sizes

```{r}
#| echo: true
#| eval: true

# Number of simulations per combination
nsim <- 1000

# Total combinations:
nrow(power_grid)
# Simulations per combination:
nsim
# Total simulations:
nrow(power_grid) * nsim
```

## Part 8: Power analysis across varying sample sizes and effect sizes

- I ran the power analysis and saved the outputto "power_grid_log_crossed.RData" it took 5.34 hours to finish

```{r}
#| echo: true
#| eval: false

# Run the power simulations, if you have the time
tic()
for(row in 1:nrow(power_grid)){
  n_subj <- power_grid$n[row]
  effect <- power_grid$b1[row]

  cat(sprintf("Running: n=%d, b1=%.2f (%d/%d)\n",
              n_subj, effect, row, nrow(power_grid)))

  pvals <- rep(NA, nsim)

  for(i in 1:nsim){
    sim_dat <- gendat_ldt_crossed_log(n = n_subj,
                                      k = n_item,
                                      b0 = 6.59,
                                      b1 = effect,
                                      sigma_u0 = 0.2,
                                      sigma_u1 = 0.02,
                                      rho = -0.5,
                                      sigma_w = 0.1,
                                      sigma = 0.25)

    m <- lmer(log(rt) ~ cond.cod + (1 + cond.cod|subj) + (1|item), sim_dat,
              control = lmerControl(calc.derivs = FALSE))

    pvals[i] <- summary(m)$coefficients[2,5]
  }
  power_grid$power[row] <- mean(pvals < 0.05)
}
toc() # 19246.916 sec elapsed = 5.34h

# save(power_grid, file = "power_grid_sub_eff.RData")
```


## Part 8: Power analysis across varying sample sizes and effect sizes

**Load and view the power grid results:**

```{r}
#| echo: true
#| eval: true
#| output-location: fragment

load("power_grid_sub_eff.RData")
power_grid
```

## Part 8: Power analysis across varying sample sizes and effect sizes

**Calculate confidence intervals for power estimates (see the script):**

```{r}
#| echo: false
#| eval: true

# Add confidence intervals

# Function to calculate binomial confidence intervals
calculate_power_ci <- function(n_significant, n_total, conf.level = 0.95) {
  # Handle edge cases
  if (is.na(n_significant) || is.na(n_total) || n_total == 0) {
    return(c(power = NA, lower = NA, upper = NA))
  }

  # Ensure inputs are proper integers
  n_significant <- as.integer(round(n_significant))
  n_total <- as.integer(round(n_total))

  # Ensure n_significant is within valid range
  if (n_significant < 0) n_significant <- 0
  if (n_significant > n_total) n_significant <- n_total

  # Exact binomial confidence interval (Clopper-Pearson method)
  test_result <- binom.test(n_significant, n_total, conf.level = conf.level)

  c(power = unname(test_result$estimate),
    lower = test_result$conf.int[1],
    upper = test_result$conf.int[2])
}

# Calculate CIs for each power estimate
power_grid$lower_ci <- NA
power_grid$upper_ci <- NA
power_grid$n_sig <- round(power_grid$power * nsim)  # Number of significant results

for(row in 1:nrow(power_grid)) {
  ci_result <- calculate_power_ci(power_grid$n_sig[row], nsim)
  power_grid$lower_ci[row] <- ci_result["lower"]
  power_grid$upper_ci[row] <- ci_result["upper"]
}

# View power estimates with confidence intervals
print(power_grid[, c("n", "b1", "power", "lower_ci", "upper_ci")])
```


## Part 8: Power analysis across varying sample sizes and effect sizes

**Create power curve plot with confidence intervals:**

```{r}
#| echo: false
#| eval: true
#| fig-width: 8
#| fig-height: 6

# Add effect size labels for plotting
power_grid$effect_label <- factor(power_grid$b1,
                                  levels = c(0.06, 0.10, 0.14),
                                  labels = c("Small (b1=0.06)",
                                             "Medium (b1=0.10)",
                                             "Large (b1=0.14)"))

# Create the power curve plot WITH CONFIDENCE INTERVALS (simr-style!)
power_curves <- ggplot(power_grid, aes(x = n, y = power, color = effect_label,
                       fill = effect_label, group = effect_label)) +
  # Shaded confidence region
  geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci),
              alpha = 0.2, color = NA) +
  # Power line and points
  geom_line(linewidth = 1.2) +
  geom_point(size = 3) +
  # Reference lines
  geom_hline(yintercept = 0.80, linetype = "dashed", color = "black", linewidth = 0.8) +
  geom_hline(yintercept = 0.025, linetype = "dotted", color = "gray50") +
  geom_hline(yintercept = 0.95, linetype = "dashed", color = "black", linewidth = 0.8) +
  geom_hline(yintercept = 0.025, linetype = "dotted", color = "gray50") +
  # Scales
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
  scale_x_continuous(breaks = n_subj) +
  scale_color_manual(values = c("#E69F00", "#56B4E9", "#009E73")) +
  scale_fill_manual(values = c("#E69F00", "#56B4E9", "#009E73")) +
  # Labels
  labs(title = "Power Curves with 95% Confidence Intervals",
       subtitle = sprintf("%d simulations per point", nsim),
       x = "Number of Subjects",
       y = "Statistical Power (1 - β)",
       color = "Effect Size",
       fill = "Effect Size") +
  theme_minimal(base_size = 14) +
  theme(legend.position = "bottom",
        plot.title = element_text(face = "bold"),
        panel.grid.minor = element_blank())

power_curves
```

## Part 8: Power analysis across varying sample sizes and effect sizes

**For a complete picture, let's vary both subjects AND items.**

Let's assume our effect is relatively small (0.06 on a log scale):

```{r}
#| echo: true
#| eval: true

sample_sizes_2d <- c(24, 36, 48, 60, 72, 84, 96)
item_numbers_2d <- c(40, 60, 80, 100, 120)
effect_fixed <- 0.06

power_grid_2d <- expand.grid(n = sample_sizes_2d,
                             nitem = item_numbers_2d)
power_grid_2d$power <- NA

nsim <- 500

nrow(power_grid_2d) * nsim
```

## Part 8: Power analysis across varying sample sizes and effect sizes

**Run the power simulations, if you have the time:**

-   This power analysis took 8.37h to complete.

```{r}
#| echo: true
#| eval: false

tic()
for(row in 1:nrow(power_grid_2d)){
  n_subj <- power_grid_2d$n[row]
  n_items <- power_grid_2d$nitem[row]

  cat(sprintf("Running: n=%d, k=%d (%d/%d)\n",
              n_subj, n_items, row, nrow(power_grid_2d)))

  pvals <- rep(NA, nsim)

  for(i in 1:nsim){
    sim_dat <- gendat_ldt_crossed_log(n = n_subj,
                                      k = n_items,
                                      b0 = 6.59,
                                      b1 = effect_fixed,
                                      sigma_u0 = 0.2,
                                      sigma_u1 = 0.02,
                                      rho = -0.5,
                                      sigma_w = 0.1,
                                      sigma = 0.25)

    m <- lmer(log(rt) ~ cond.cod + (1 + cond.cod|subj) + (1|item), sim_dat,
              control = lmerControl(calc.derivs = FALSE))
    
    pvals[i] <- summary(m)$coefficients[2,5]
  }

  power_grid_2d$power[row] <- mean(pvals < 0.05)
}
toc() # 30145.484 sec elapsed = 8.37h

# save(power_grid_2d, file = "power_grid_2d.RData")
```


## Part 8: Power analysis across varying sample sizes and effect sizes

**Load and view the power grid results (previously saved):**

```{r}
#| echo: true
#| eval: true

load("power_grid_2d.RData")
power_grid_2d <- power_grid_3d
power_grid_2d
```
## Part 8: Power analysis across varying sample sizes and effect sizes

**Create power curve plot with confidence intervals:**

```{r}
#| echo: false
#| eval: true

# Add confidence intervals

# Define nsim (should match the value used in simulations)
nsim <- 500

# Calculate CIs for each power estimate in the 2D grid
power_grid_2d$lower_ci <- NA
power_grid_2d$upper_ci <- NA
power_grid_2d$n_sig <- round(power_grid_2d$power * nsim)

for(row in 1:nrow(power_grid_2d)) {
  # Only calculate CI if power is not NA
  if (!is.na(power_grid_2d$power[row])) {
    ci_result <- calculate_power_ci(power_grid_2d$n_sig[row], nsim)
    power_grid_2d$lower_ci[row] <- ci_result["lower"]
    power_grid_2d$upper_ci[row] <- ci_result["upper"]
  }
}

# View power estimates with confidence intervals
power_grid_2d[, c("n", "nitem", "power", "lower_ci", "upper_ci")]
```


## Part 8: Power analysis across varying sample sizes and effect sizes

**Visualize power across subjects and items:**

```{r}
#| echo: false
#| eval: true
#| fig-width: 8
#| fig-height: 6
#| fig-cap: "Heatmap of Power as a Function of Number of Subjects and Items"

# Create heatmap showing power for different combinations
heatmap <- ggplot(power_grid_2d, aes(x = factor(n), y = factor(nitem), fill = power)) +
  geom_tile(color = "white", size = 1) +
  geom_text(aes(label = sprintf("%.2f", power)),
            color = "white", size = 4, fontface = "bold") +
  scale_fill_gradient2(low = "#d73027", mid = "#fee08b", high = "#1a9850",
                       midpoint = 0.80, limits = c(0, 1),
                       breaks = seq(0, 1, 0.2),
                       name = "Power") +
  labs(title = "Power as a Function of Subjects and Items",
       subtitle = sprintf("Effect size: b1=%.2f (log scale), %d simulations per point",
                          effect_fixed, nsim),
       x = "Number of Subjects",
       y = "Number of Items") +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(face = "bold"),
        panel.grid = element_blank())

heatmap
```

## Part 8: Power analysis across varying sample sizes and effect sizes

**Next steps:**

-   Concentrate on the range where you get 80% and 95% power. Run more simulations with more granular steps (subjects, items) in the range identified above.

## In this section we have:

-   ...done power analysis for three different effect sizes (0.6, 10, 0.14) across varying sample sizes.
-   ...done power analysis varying both subjects and items.


## The final model we have created:

$$
log(rt_{ij}) = \beta_0 + u_{0i} + w_{0j} + (\beta_1 + u_{1i}) \times cond.cod_{ij} + \varepsilon_{ij}
$$ where $\varepsilon_{ij} \sim Normal(0, \sigma)$ and

$$
\begin{pmatrix} u_0 \\ u_1 \end{pmatrix} \sim MVN \left( \begin{pmatrix} 0 \\ 0 \end{pmatrix}, \Sigma_u \right), \quad
$$

$$
\Sigma_u = \begin{pmatrix}
\sigma_{u0}^2 & \rho_u \sigma_{u0} \sigma_{u1} \\
\rho_u \sigma_{u0} \sigma_{u1} & \sigma_{u1}^2
\end{pmatrix} \quad
$$ $$
\ w_0 \sim N (0, \sigma_w)
$$

## Part 8: Power analysis across varying sample sizes and effect sizes

**Where to go next:**

-   Similar examples covered here: https://vasishth.github.io/Freq_CogSci/using-simulation-to-understand-your-model.html
-   Power analysis with Julia: https://repsychling.github.io/MixedModelsSim.jl/stable/simulation_tutorial/

## Preguntas? {background-color="#43464B"}